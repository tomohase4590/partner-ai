# """
# ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚³ã‚¢
# FastAPI + Ollama + SQLite
# """

# from fastapi import FastAPI, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel
# from typing import List, Optional, Dict
# import ollama
# import sqlite3
# import json
# from datetime import datetime
# import os
# from analyzer import ConversationAnalyzer, ProfileManager
# from rag_system import RAGSystem, SelfImprovementSystem

# # FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
# app = FastAPI(title="ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI API")

# # CORSè¨­å®šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ï¼‰
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
# DB_PATH = "partner_ai.db"

# # ==================== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ– ====================

# def init_db():
#     """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
#     conn = sqlite3.connect(DB_PATH)
#     c = conn.cursor()
    
#     # ä¼šè©±ãƒ†ãƒ¼ãƒ–ãƒ«
#     c.execute("""
#         CREATE TABLE IF NOT EXISTS conversations (
#             id INTEGER PRIMARY KEY AUTOINCREMENT,
#             user_id TEXT NOT NULL,
#             timestamp TEXT NOT NULL,
#             user_message TEXT NOT NULL,
#             ai_response TEXT NOT NULL,
#             model_used TEXT,
#             rating INTEGER,
#             tags TEXT,
#             metadata TEXT
#         )
#     """)
    
#     # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
#     c.execute("""
#         CREATE TABLE IF NOT EXISTS user_profiles (
#             user_id TEXT PRIMARY KEY,
#             profile_data TEXT NOT NULL,
#             created_at TEXT NOT NULL,
#             updated_at TEXT NOT NULL
#         )
#     """)
    
#     conn.commit()
#     conn.close()
#     print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")

# # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å®Ÿè¡Œ
# init_db()

# # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
# analyzer = ConversationAnalyzer(model="gemma3:4b")
# rag_system = RAGSystem(persist_directory="./chroma_db")
# print(f"âœ… RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

# # ==================== Pydanticãƒ¢ãƒ‡ãƒ« ====================

# class ChatRequest(BaseModel):
#     user_id: str
#     message: str
#     model: Optional[str] = "qwen2.5:32b"

# class ChatResponse(BaseModel):
#     conversation_id: int
#     response: str
#     model_used: str
#     timestamp: str
#     reason: Optional[str] = None
#     tags: Optional[List[str]] = None

# class FeedbackRequest(BaseModel):
#     conversation_id: int
#     rating: int
#     comment: Optional[str] = None

# class HistoryResponse(BaseModel):
#     conversations: List[Dict]
#     total: int

# # ==================== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ====================

# def get_user_profile(user_id: str) -> Dict:
#     """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
#     conn = sqlite3.connect(DB_PATH)
#     profile_manager = ProfileManager(conn)
#     profile = profile_manager.get_profile(user_id)
#     conn.close()
#     return profile

# def save_conversation(
#     user_id: str,
#     user_msg: str,
#     ai_msg: str,
#     model: str,
#     metadata: Dict = None
# ) -> int:
#     """ä¼šè©±ã‚’ä¿å­˜"""
#     conn = sqlite3.connect(DB_PATH)
#     c = conn.cursor()
    
#     timestamp = datetime.now().isoformat()
#     metadata_json = json.dumps(metadata, ensure_ascii=False) if metadata else "{}"
    
#     c.execute("""
#         INSERT INTO conversations 
#         (user_id, timestamp, user_message, ai_response, model_used, metadata)
#         VALUES (?, ?, ?, ?, ?, ?)
#     """, (user_id, timestamp, user_msg, ai_msg, model, metadata_json))
    
#     conv_id = c.lastrowid
#     conn.commit()
#     conn.close()
    
#     return conv_id

# def get_recent_history(user_id: str, limit: int = 5) -> List[Dict]:
#     """æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
#     conn = sqlite3.connect(DB_PATH)
#     c = conn.cursor()
    
#     c.execute("""
#         SELECT user_message, ai_response, timestamp
#         FROM conversations
#         WHERE user_id = ?
#         ORDER BY timestamp DESC
#         LIMIT ?
#     """, (user_id, limit))
    
#     rows = c.fetchall()
#     conn.close()
    
#     history = []
#     for row in reversed(rows):  # å¤ã„é †ã«ä¸¦ã¹æ›¿ãˆ
#         history.append({
#             "user": row[0],
#             "ai": row[1],
#             "timestamp": row[2]
#         })
    
#     return history

# def build_system_prompt(profile: Dict) -> str:
#     """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
#     conn = sqlite3.connect(DB_PATH)
#     profile_manager = ProfileManager(conn)
#     # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
#     # user_idã¯ä¸è¦ãªã®ã§ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ—¢ã«profileãŒã‚ã‚‹ï¼‰
#     prompt = profile_manager.get_personalized_system_prompt("dummy")
#     conn.close()
    
#     # profileã®å†…å®¹ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
#     base = "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
    
#     if profile.get("interests"):
#         interests = ", ".join(profile["interests"])
#         base += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™: {interests}\n"
    
#     if profile.get("memories"):
#         base += "\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¤ã„ã¦å­¦ç¿’ã—ãŸæƒ…å ±:\n"
#         for mem in profile["memories"][-3:]:
#             base += f"- {mem}\n"
    
#     return base

# # ==================== APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ====================

# @app.get("/")
# async def root():
#     """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
#     return {
#         "status": "ok",
#         "message": "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒç¨¼åƒä¸­",
#         "version": "1.0.0"
#     }

# @app.post("/api/chat", response_model=ChatResponse)
# async def chat(req: ChatRequest):
#     """ãƒãƒ£ãƒƒãƒˆAPI"""
#     try:
#         # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
#         profile = get_user_profile(req.user_id)
        
#         # å±¥æ­´å–å¾—
#         history = get_recent_history(req.user_id, limit=5)
        
#         # RAGã§é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’æ¤œç´¢
#         relevant_memories = rag_system.search_relevant_memories(
#             user_id=req.user_id,
#             query=req.message,
#             n_results=3
#         )
        
#         # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
#         system_prompt = build_system_prompt(profile)
        
#         # é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’è¿½åŠ 
#         if relevant_memories:
#             system_prompt += "\n\néå»ã®é–¢é€£ã™ã‚‹ä¼šè©±:\n"
#             for mem in relevant_memories:
#                 system_prompt += f"- {mem['user_message'][:100]}...\n"
        
#         # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
#         messages = [
#             {"role": "system", "content": system_prompt}
#         ]
        
#         # å±¥æ­´è¿½åŠ 
#         for h in history:
#             messages.append({"role": "user", "content": h["user"]})
#             messages.append({"role": "assistant", "content": h["ai"]})
        
#         # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
#         messages.append({"role": "user", "content": req.message})
        
#         # Ollamaå‘¼ã³å‡ºã—
#         print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ« {req.model} ã§æ¨è«–ä¸­...")
#         response = ollama.chat(
#             model=req.model,
#             messages=messages,
#             options={
#                 "temperature": 0.7,
#                 "num_ctx": 8192,
#             }
#         )
        
#         ai_response = response['message']['content']
        
#         # å¿œç­”ç†ç”±ã‚’ç”Ÿæˆ
#         reason = generate_response_reason(req.message, ai_response, profile, relevant_memories)
        
#         # ã‚¿ã‚°ã‚’è‡ªå‹•ç”Ÿæˆ
#         tags = analyzer.extract_topics_simple(f"{req.message} {ai_response}")
        
#         # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
#         metadata = {
#             "reason": reason,
#             "tags": tags,
#             "relevant_memories_count": len(relevant_memories),
#             "model_params": {
#                 "temperature": 0.7,
#                 "context_length": 8192
#             }
#         }
        
#         # ä¼šè©±ã‚’ä¿å­˜
#         conv_id = save_conversation(
#             user_id=req.user_id,
#             user_msg=req.message,
#             ai_msg=ai_response,
#             model=req.model,
#             metadata=metadata
#         )
        
#         # RAGã«è¨˜æ†¶ã‚’è¿½åŠ 
#         rag_system.add_memory(
#             user_id=req.user_id,
#             conversation_id=conv_id,
#             user_message=req.message,
#             ai_response=ai_response,
#             metadata={"tags": tags}
#         )
        
#         # ä¼šè©±ã‚’åˆ†æã—ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
#         try:
#             analysis = analyzer.analyze_conversation(req.message, ai_response)
            
#             conn = sqlite3.connect(DB_PATH)
#             profile_manager = ProfileManager(conn)
#             updated_profile = profile_manager.update_profile(req.user_id, analysis)
#             conn.close()
            
#             print(f"âœ… ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {updated_profile.get('interests', [])}")
#         except Exception as e:
#             print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        
#         print(f"âœ… å¿œç­”å®Œäº† (ID: {conv_id})")
        
#         return ChatResponse(
#             conversation_id=conv_id,
#             response=ai_response,
#             model_used=req.model,
#             timestamp=datetime.now().isoformat(),
#             reason=reason,
#             tags=tags
#         )
        
#     except Exception as e:
#         print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))


# def generate_response_reason(
#     user_message: str,
#     ai_response: str,
#     profile: Dict,
#     memories: List[Dict]
# ) -> str:
#     """å¿œç­”ç†ç”±ã‚’ç”Ÿæˆ"""
    
#     reasons = []
    
#     # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãç†ç”±
#     if profile.get("interests"):
#         interests = ", ".join(profile["interests"][:2])
#         reasons.append(f"ã‚ãªãŸã®èˆˆå‘³({interests})ã‚’è€ƒæ…®ã—ã¾ã—ãŸ")
    
#     # è¨˜æ†¶ã«åŸºã¥ãç†ç”±
#     if memories:
#         reasons.append(f"éå»ã®{len(memories)}ä»¶ã®é–¢é€£ä¼šè©±ã‚’å‚ç…§ã—ã¾ã—ãŸ")
    
#     # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç‰¹æ€§
#     if "?" in user_message or "ï¼Ÿ" in user_message:
#         reasons.append("è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
#     elif len(user_message) > 100:
#         reasons.append("è©³ç´°ãªè³ªå•ã«å¯¾ã—ã¦ä¸å¯§ã«å›ç­”ã—ã¾ã—ãŸ")
#     else:
#         reasons.append("ç°¡æ½”ãªå¿œç­”ã‚’å¿ƒãŒã‘ã¾ã—ãŸ")
    
#     return "ã€".join(reasons) if reasons else "ä¸€èˆ¬çš„ãªçŸ¥è­˜ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã—ãŸ"

# @app.get("/api/history/{user_id}", response_model=HistoryResponse)
# async def get_history(user_id: str, limit: int = 50):
#     """ä¼šè©±å±¥æ­´å–å¾—"""
#     try:
#         conn = sqlite3.connect(DB_PATH)
#         c = conn.cursor()
        
#         c.execute("""
#             SELECT id, timestamp, user_message, ai_response, model_used, rating, metadata
#             FROM conversations
#             WHERE user_id = ?
#             ORDER BY timestamp DESC
#             LIMIT ?
#         """, (user_id, limit))
        
#         rows = c.fetchall()
#         conn.close()
        
#         conversations = []
#         for row in rows:
#             metadata = json.loads(row[6]) if row[6] else {}
            
#             conversations.append({
#                 "id": row[0],
#                 "timestamp": row[1],
#                 "user_message": row[2],
#                 "ai_response": row[3],
#                 "model_used": row[4],
#                 "rating": row[5],
#                 "tags": metadata.get("tags", []),
#                 "reason": metadata.get("reason", "")
#             })
        
#         return HistoryResponse(
#             conversations=conversations,
#             total=len(conversations)
#         )
        
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/feedback")
# async def submit_feedback(req: FeedbackRequest):
#     """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜"""
#     try:
#         conn = sqlite3.connect(DB_PATH)
#         c = conn.cursor()
        
#         # ç¾åœ¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
#         c.execute("SELECT metadata FROM conversations WHERE id = ?", (req.conversation_id,))
#         row = c.fetchone()
        
#         if row:
#             metadata = json.loads(row[0]) if row[0] else {}
#         else:
#             metadata = {}
        
#         # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿½åŠ 
#         metadata["feedback_rating"] = req.rating
#         if req.comment:
#             metadata["feedback_comment"] = req.comment
#         metadata["feedback_timestamp"] = datetime.now().isoformat()
        
#         # æ›´æ–°
#         c.execute("""
#             UPDATE conversations
#             SET rating = ?, metadata = ?
#             WHERE id = ?
#         """, (req.rating, json.dumps(metadata, ensure_ascii=False), req.conversation_id))
        
#         conn.commit()
        
#         # è‡ªå·±æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œï¼ˆä½è©•ä¾¡ã®å ´åˆï¼‰
#         if req.rating <= 2:
#             c.execute("SELECT user_id FROM conversations WHERE id = ?", (req.conversation_id,))
#             user_row = c.fetchone()
            
#             if user_row:
#                 user_id = user_row[0]
#                 improvement_system = SelfImprovementSystem(conn)
#                 improvements = improvement_system.analyze_feedback(user_id)
                
#                 if improvements["suggestions"]:
#                     improvement_system.apply_improvements(user_id, improvements)
#                     print(f"âœ… è‡ªå·±æ”¹è‰¯å®Ÿè¡Œ: {improvements['suggestions']}")
        
#         conn.close()
        
#         print(f"âœ… ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ (ID: {req.conversation_id}, Rating: {req.rating})")
        
#         return {"status": "success", "message": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ"}
        
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.get("/api/models")
# async def list_models():
#     """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§"""
#     try:
#         result = ollama.list()
#         models = []
#         # ListResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ç›´æ¥modelsã‚’å–å¾—
#         model_list = result.models if hasattr(result, 'models') else []

#         for m in model_list:
#             # Modelã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å±æ€§ã‚’å–å¾—
#             name = m.model if hasattr(m, 'model') else str(m)
#             size = m.size if hasattr(m, 'size') else 0

#             # è©³ç´°æƒ…å ±ã‚’å–å¾—
#             details = m.details if hasattr(m, 'details') else None
#             param_size = details.parameter_size if details and hasattr(details, 'parameter_size') else ''
#             quant = details.quantization_level if details and hasattr(details, 'quantization_level') else ''
            
#             models.append({
#                 "name": name,
#                 "size": size,
#                 "size_gb": round(size / (1024**3), 1),
#                 "parameter_size": param_size,
#                 "quantization": quant
#             })
        
#         return {"models": models}

#     except Exception as e:
#         print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
#         import traceback
#         traceback.print_exc()
#         raise HTTPException(status_code=500, detail=str(e))

# @app.get("/api/stats/{user_id}")
# async def get_stats(user_id: str):
#     """ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆ"""
#     try:
#         conn = sqlite3.connect(DB_PATH)
#         c = conn.cursor()
        
#         # ç·ä¼šè©±æ•°
#         c.execute("SELECT COUNT(*) FROM conversations WHERE user_id = ?", (user_id,))
#         total_conversations = c.fetchone()[0]
        
#         # å¹³å‡è©•ä¾¡
#         c.execute("""
#             SELECT AVG(rating) 
#             FROM conversations 
#             WHERE user_id = ? AND rating IS NOT NULL
#         """, (user_id,))
#         avg_rating = c.fetchone()[0] or 0
        
#         # ã‚ˆãä½¿ã†ãƒ¢ãƒ‡ãƒ«
#         c.execute("""
#             SELECT model_used, COUNT(*) as count
#             FROM conversations
#             WHERE user_id = ?
#             GROUP BY model_used
#             ORDER BY count DESC
#             LIMIT 1
#         """, (user_id,))
#         most_used_model = c.fetchone()
        
#         conn.close()
        
#         return {
#             "total_conversations": total_conversations,
#             "average_rating": round(avg_rating, 2),
#             "most_used_model": most_used_model[0] if most_used_model else None
#         }
        
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))
    

# @app.get("/api/profile/{user_id}")
# async def get_profile_endpoint(user_id: str):
#     """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
#     try:
#         profile = get_user_profile(user_id)
        
#         # RAGã®è¨˜æ†¶æ•°ã‚’è¿½åŠ 
#         memory_count = rag_system.get_memory_count(user_id)
#         profile["rag_memories"] = memory_count
        
#         return {"profile": profile}
#     except Exception as e:
#         print(f"âŒ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
#         import traceback
#         traceback.print_exc()
#         raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/improve/{user_id}")
# async def trigger_improvement(user_id: str):
#     """æ‰‹å‹•ã§è‡ªå·±æ”¹è‰¯ã‚’å®Ÿè¡Œ"""
#     try:
#         conn = sqlite3.connect(DB_PATH)
#         improvement_system = SelfImprovementSystem(conn)
        
#         improvements = improvement_system.analyze_feedback(user_id)
#         updated_profile = improvement_system.apply_improvements(user_id, improvements)
        
#         conn.close()
        
#         return {
#             "status": "success",
#             "improvements": improvements,
#             "updated_profile": updated_profile
#         }
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# @app.post("/api/conversation/{conversation_id}/tags")
# async def update_conversation_tags(conversation_id: int, tags: List[str]):
#     """ä¼šè©±ã®ã‚¿ã‚°ã‚’æ›´æ–°"""
#     try:
#         conn = sqlite3.connect(DB_PATH)
#         c = conn.cursor()
        
#         # ç¾åœ¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
#         c.execute("SELECT metadata FROM conversations WHERE id = ?", (conversation_id,))
#         row = c.fetchone()
        
#         if row:
#             metadata = json.loads(row[0]) if row[0] else {}
#         else:
#             raise HTTPException(status_code=404, detail="Conversation not found")
        
#         # ã‚¿ã‚°ã‚’æ›´æ–°
#         metadata["tags"] = tags
        
#         # ä¿å­˜
#         c.execute("""
#             UPDATE conversations
#             SET metadata = ?
#             WHERE id = ?
#         """, (json.dumps(metadata, ensure_ascii=False), conversation_id))
        
#         conn.commit()
#         conn.close()
        
#         return {"status": "success", "tags": tags}
        
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=str(e))

# # ==================== èµ·å‹• ====================

# if __name__ == "__main__":
#     import uvicorn
    
#     print("=" * 50)
#     print("ğŸš€ ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰èµ·å‹•ä¸­...")
#     print("=" * 50)
#     print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {DB_PATH}")
#     print(f"ğŸŒ API: http://localhost:8000")
#     print(f"ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://localhost:8000/docs")
#     print("=" * 50)
    
#     uvicorn.run(app, host="0.0.0.0", port=8000)






"""
ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚³ã‚¢
FastAPI + Ollama + SQLite
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict
import ollama
import sqlite3
import json
from datetime import datetime
import os
from analyzer import ConversationAnalyzer, ProfileManager
from rag_system import RAGSystem, SelfImprovementSystem
from finetuning import FineTuningSystem

# FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
app = FastAPI(title="ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI API")

# CORSè¨­å®šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«
DB_PATH = "partner_ai.db"

# ==================== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ– ====================

def init_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # ä¼šè©±ãƒ†ãƒ¼ãƒ–ãƒ«
    c.execute("""
        CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT NOT NULL,
            timestamp TEXT NOT NULL,
            user_message TEXT NOT NULL,
            ai_response TEXT NOT NULL,
            model_used TEXT,
            rating INTEGER,
            tags TEXT,
            metadata TEXT
        )
    """)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
    c.execute("""
        CREATE TABLE IF NOT EXISTS user_profiles (
            user_id TEXT PRIMARY KEY,
            profile_data TEXT NOT NULL,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL
        )
    """)
    
    conn.commit()
    conn.close()
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«å®Ÿè¡Œ
init_db()

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
analyzer = ConversationAnalyzer(model="gemma3:4b")
rag_system = RAGSystem(persist_directory="./chroma_db")
print(f"âœ… RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

# ==================== Pydanticãƒ¢ãƒ‡ãƒ« ====================

class ChatRequest(BaseModel):
    user_id: str
    message: str
    model: Optional[str] = "qwen2.5:32b"

class ChatResponse(BaseModel):
    conversation_id: int
    response: str
    model_used: str
    timestamp: str
    reason: Optional[str] = None
    tags: Optional[List[str]] = None

class FeedbackRequest(BaseModel):
    conversation_id: int
    rating: int
    comment: Optional[str] = None

class HistoryResponse(BaseModel):
    conversations: List[Dict]
    total: int

# ==================== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ====================

def get_user_profile(user_id: str) -> Dict:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
    conn = sqlite3.connect(DB_PATH)
    profile_manager = ProfileManager(conn)
    profile = profile_manager.get_profile(user_id)
    conn.close()
    return profile

def save_conversation(
    user_id: str,
    user_msg: str,
    ai_msg: str,
    model: str,
    metadata: Dict = None
) -> int:
    """ä¼šè©±ã‚’ä¿å­˜"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    timestamp = datetime.now().isoformat()
    metadata_json = json.dumps(metadata, ensure_ascii=False) if metadata else "{}"
    
    c.execute("""
        INSERT INTO conversations 
        (user_id, timestamp, user_message, ai_response, model_used, metadata)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (user_id, timestamp, user_msg, ai_msg, model, metadata_json))
    
    conv_id = c.lastrowid
    conn.commit()
    conn.close()
    
    return conv_id

def get_recent_history(user_id: str, limit: int = 5) -> List[Dict]:
    """æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    c.execute("""
        SELECT user_message, ai_response, timestamp
        FROM conversations
        WHERE user_id = ?
        ORDER BY timestamp DESC
        LIMIT ?
    """, (user_id, limit))
    
    rows = c.fetchall()
    conn.close()
    
    history = []
    for row in reversed(rows):  # å¤ã„é †ã«ä¸¦ã¹æ›¿ãˆ
        history.append({
            "user": row[0],
            "ai": row[1],
            "timestamp": row[2]
        })
    
    return history

def build_system_prompt(profile: Dict) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
    conn = sqlite3.connect(DB_PATH)
    profile_manager = ProfileManager(conn)
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    # user_idã¯ä¸è¦ãªã®ã§ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ—¢ã«profileãŒã‚ã‚‹ï¼‰
    prompt = profile_manager.get_personalized_system_prompt("dummy")
    conn.close()
    
    # profileã®å†…å®¹ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
    base = "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
    
    if profile.get("interests"):
        interests = ", ".join(profile["interests"])
        base += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™: {interests}\n"
    
    if profile.get("memories"):
        base += "\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¤ã„ã¦å­¦ç¿’ã—ãŸæƒ…å ±:\n"
        for mem in profile["memories"][-3:]:
            base += f"- {mem}\n"
    
    return base

# ==================== APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ====================

@app.get("/")
async def root():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ok",
        "message": "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒç¨¼åƒä¸­",
        "version": "1.0.0"
    }

@app.post("/api/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    """ãƒãƒ£ãƒƒãƒˆAPI"""
    try:
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        profile = get_user_profile(req.user_id)
        
        # å±¥æ­´å–å¾—
        history = get_recent_history(req.user_id, limit=5)
        
        # RAGã§é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’æ¤œç´¢
        relevant_memories = rag_system.search_relevant_memories(
            user_id=req.user_id,
            query=req.message,
            n_results=3
        )
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = build_system_prompt(profile)
        
        # é–¢é€£ã™ã‚‹è¨˜æ†¶ã‚’è¿½åŠ 
        if relevant_memories:
            system_prompt += "\n\néå»ã®é–¢é€£ã™ã‚‹ä¼šè©±:\n"
            for mem in relevant_memories:
                system_prompt += f"- {mem['user_message'][:100]}...\n"
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # å±¥æ­´è¿½åŠ 
        for h in history:
            messages.append({"role": "user", "content": h["user"]})
            messages.append({"role": "assistant", "content": h["ai"]})
        
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        messages.append({"role": "user", "content": req.message})
        
        # Ollamaå‘¼ã³å‡ºã—
        print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ« {req.model} ã§æ¨è«–ä¸­...")
        response = ollama.chat(
            model=req.model,
            messages=messages,
            options={
                "temperature": 0.7,
                "num_ctx": 8192,
            }
        )
        
        ai_response = response['message']['content']
        
        # å¿œç­”ç†ç”±ã‚’ç”Ÿæˆ
        reason = generate_response_reason(req.message, ai_response, profile, relevant_memories)
        
        # ã‚¿ã‚°ã‚’è‡ªå‹•ç”Ÿæˆ
        tags = analyzer.extract_topics_simple(f"{req.message} {ai_response}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        metadata = {
            "reason": reason,
            "tags": tags,
            "relevant_memories_count": len(relevant_memories),
            "model_params": {
                "temperature": 0.7,
                "context_length": 8192
            }
        }
        
        # ä¼šè©±ã‚’ä¿å­˜
        conv_id = save_conversation(
            user_id=req.user_id,
            user_msg=req.message,
            ai_msg=ai_response,
            model=req.model,
            metadata=metadata
        )
        
        # RAGã«è¨˜æ†¶ã‚’è¿½åŠ 
        rag_system.add_memory(
            user_id=req.user_id,
            conversation_id=conv_id,
            user_message=req.message,
            ai_response=ai_response,
            metadata={"tags": tags}
        )
        
        # ä¼šè©±ã‚’åˆ†æã—ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        try:
            analysis = analyzer.analyze_conversation(req.message, ai_response)
            
            conn = sqlite3.connect(DB_PATH)
            profile_manager = ProfileManager(conn)
            updated_profile = profile_manager.update_profile(req.user_id, analysis)
            conn.close()
            
            print(f"âœ… ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°å®Œäº†: {updated_profile.get('interests', [])}")
        except Exception as e:
            print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"âœ… å¿œç­”å®Œäº† (ID: {conv_id})")
        
        return ChatResponse(
            conversation_id=conv_id,
            response=ai_response,
            model_used=req.model,
            timestamp=datetime.now().isoformat(),
            reason=reason,
            tags=tags
        )
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


def generate_response_reason(
    user_message: str,
    ai_response: str,
    profile: Dict,
    memories: List[Dict]
) -> str:
    """å¿œç­”ç†ç”±ã‚’ç”Ÿæˆ"""
    
    reasons = []
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãç†ç”±
    if profile.get("interests"):
        interests = ", ".join(profile["interests"][:2])
        reasons.append(f"ã‚ãªãŸã®èˆˆå‘³({interests})ã‚’è€ƒæ…®ã—ã¾ã—ãŸ")
    
    # è¨˜æ†¶ã«åŸºã¥ãç†ç”±
    if memories:
        reasons.append(f"éå»ã®{len(memories)}ä»¶ã®é–¢é€£ä¼šè©±ã‚’å‚ç…§ã—ã¾ã—ãŸ")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç‰¹æ€§
    if "?" in user_message or "ï¼Ÿ" in user_message:
        reasons.append("è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    elif len(user_message) > 100:
        reasons.append("è©³ç´°ãªè³ªå•ã«å¯¾ã—ã¦ä¸å¯§ã«å›ç­”ã—ã¾ã—ãŸ")
    else:
        reasons.append("ç°¡æ½”ãªå¿œç­”ã‚’å¿ƒãŒã‘ã¾ã—ãŸ")
    
    return "ã€".join(reasons) if reasons else "ä¸€èˆ¬çš„ãªçŸ¥è­˜ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã—ãŸ"

@app.get("/api/history/{user_id}", response_model=HistoryResponse)
async def get_history(user_id: str, limit: int = 50):
    """ä¼šè©±å±¥æ­´å–å¾—"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        c.execute("""
            SELECT id, timestamp, user_message, ai_response, model_used, rating, metadata
            FROM conversations
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, limit))
        
        rows = c.fetchall()
        conn.close()
        
        conversations = []
        for row in rows:
            metadata = json.loads(row[6]) if row[6] else {}
            
            conversations.append({
                "id": row[0],
                "timestamp": row[1],
                "user_message": row[2],
                "ai_response": row[3],
                "model_used": row[4],
                "rating": row[5],
                "tags": metadata.get("tags", []),
                "reason": metadata.get("reason", "")
            })
        
        return HistoryResponse(
            conversations=conversations,
            total=len(conversations)
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/feedback")
async def submit_feedback(req: FeedbackRequest):
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        # ç¾åœ¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        c.execute("SELECT metadata FROM conversations WHERE id = ?", (req.conversation_id,))
        row = c.fetchone()
        
        if row:
            metadata = json.loads(row[0]) if row[0] else {}
        else:
            metadata = {}
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¿½åŠ 
        metadata["feedback_rating"] = req.rating
        if req.comment:
            metadata["feedback_comment"] = req.comment
        metadata["feedback_timestamp"] = datetime.now().isoformat()
        
        # æ›´æ–°
        c.execute("""
            UPDATE conversations
            SET rating = ?, metadata = ?
            WHERE id = ?
        """, (req.rating, json.dumps(metadata, ensure_ascii=False), req.conversation_id))
        
        conn.commit()
        
        # è‡ªå·±æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œï¼ˆä½è©•ä¾¡ã®å ´åˆï¼‰
        if req.rating <= 2:
            c.execute("SELECT user_id FROM conversations WHERE id = ?", (req.conversation_id,))
            user_row = c.fetchone()
            
            if user_row:
                user_id = user_row[0]
                improvement_system = SelfImprovementSystem(conn)
                improvements = improvement_system.analyze_feedback(user_id)
                
                if improvements["suggestions"]:
                    improvement_system.apply_improvements(user_id, improvements)
                    print(f"âœ… è‡ªå·±æ”¹è‰¯å®Ÿè¡Œ: {improvements['suggestions']}")
        
        conn.close()
        
        print(f"âœ… ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ (ID: {req.conversation_id}, Rating: {req.rating})")
        
        return {"status": "success", "message": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§"""
    try:
        result = ollama.list()
        models = []
        # ListResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ç›´æ¥modelsã‚’å–å¾—
        model_list = result.models if hasattr(result, 'models') else []

        for m in model_list:
            # Modelã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å±æ€§ã‚’å–å¾—
            name = m.model if hasattr(m, 'model') else str(m)
            size = m.size if hasattr(m, 'size') else 0

            # è©³ç´°æƒ…å ±ã‚’å–å¾—
            details = m.details if hasattr(m, 'details') else None
            param_size = details.parameter_size if details and hasattr(details, 'parameter_size') else ''
            quant = details.quantization_level if details and hasattr(details, 'quantization_level') else ''
            
            models.append({
                "name": name,
                "size": size,
                "size_gb": round(size / (1024**3), 1),
                "parameter_size": param_size,
                "quantization": quant
            })
        
        return {"models": models}

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats/{user_id}")
async def get_stats(user_id: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆ"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        # ç·ä¼šè©±æ•°
        c.execute("SELECT COUNT(*) FROM conversations WHERE user_id = ?", (user_id,))
        total_conversations = c.fetchone()[0]
        
        # å¹³å‡è©•ä¾¡
        c.execute("""
            SELECT AVG(rating) 
            FROM conversations 
            WHERE user_id = ? AND rating IS NOT NULL
        """, (user_id,))
        avg_rating = c.fetchone()[0] or 0
        
        # ã‚ˆãä½¿ã†ãƒ¢ãƒ‡ãƒ«
        c.execute("""
            SELECT model_used, COUNT(*) as count
            FROM conversations
            WHERE user_id = ?
            GROUP BY model_used
            ORDER BY count DESC
            LIMIT 1
        """, (user_id,))
        most_used_model = c.fetchone()
        
        conn.close()
        
        return {
            "total_conversations": total_conversations,
            "average_rating": round(avg_rating, 2),
            "most_used_model": most_used_model[0] if most_used_model else None
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/models")
async def list_models():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§"""
    try:
        result = ollama.list()
        models = []
        # ListResponseã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ç›´æ¥modelsã‚’å–å¾—
        model_list = result.models if hasattr(result, 'models') else []

        for m in model_list:
            # Modelã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å±æ€§ã‚’å–å¾—
            name = m.model if hasattr(m, 'model') else str(m)
            size = m.size if hasattr(m, 'size') else 0

            # è©³ç´°æƒ…å ±ã‚’å–å¾—
            details = m.details if hasattr(m, 'details') else None
            param_size = details.parameter_size if details and hasattr(details, 'parameter_size') else ''
            quant = details.quantization_level if details and hasattr(details, 'quantization_level') else ''
            
            models.append({
                "name": name,
                "size": size,
                "size_gb": round(size / (1024**3), 1),
                "parameter_size": param_size,
                "quantization": quant
            })
        
        return {"models": models}

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/profile/{user_id}")
async def get_profile_endpoint(user_id: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
    try:
        profile = get_user_profile(user_id)
        
        # RAGã®è¨˜æ†¶æ•°ã‚’è¿½åŠ 
        memory_count = rag_system.get_memory_count(user_id)
        profile["rag_memories"] = memory_count
        
        return {"profile": profile}
    except Exception as e:
        print(f"âŒ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/improve/{user_id}")
async def trigger_improvement(user_id: str):
    """æ‰‹å‹•ã§è‡ªå·±æ”¹è‰¯ã‚’å®Ÿè¡Œ"""
    try:
        conn = sqlite3.connect(DB_PATH)
        improvement_system = SelfImprovementSystem(conn)
        
        improvements = improvement_system.analyze_feedback(user_id)
        updated_profile = improvement_system.apply_improvements(user_id, improvements)
        
        conn.close()
        
        return {
            "status": "success",
            "improvements": improvements,
            "updated_profile": updated_profile
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/conversation/{conversation_id}/tags")
async def update_conversation_tags(conversation_id: int, tags: List[str]):
    """ä¼šè©±ã®ã‚¿ã‚°ã‚’æ›´æ–°"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        # ç¾åœ¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        c.execute("SELECT metadata FROM conversations WHERE id = ?", (conversation_id,))
        row = c.fetchone()
        
        if row:
            metadata = json.loads(row[0]) if row[0] else {}
        else:
            raise HTTPException(status_code=404, detail="Conversation not found")
        
        # ã‚¿ã‚°ã‚’æ›´æ–°
        metadata["tags"] = tags
        
        # ä¿å­˜
        c.execute("""
            UPDATE conversations
            SET metadata = ?
            WHERE id = ?
        """, (json.dumps(metadata, ensure_ascii=False), conversation_id))
        
        conn.commit()
        conn.close()
        
        return {"status": "success", "tags": tags}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
# ==================== èµ·å‹• ====================

if __name__ == "__main__":
    import uvicorn
    
    print("=" * 50)
    print("ğŸš€ ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼AI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰èµ·å‹•ä¸­...")
    print("=" * 50)
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {DB_PATH}")
    print(f"ğŸŒ API: http://localhost:8000")
    print(f"ğŸ“– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: http://localhost:8000/docs")
    print("=" * 50)
    
    uvicorn.run(app, host="0.0.0.0", port=8000)