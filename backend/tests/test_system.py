"""
çµ±åˆãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
RAGã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å­¦ç¿’ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’æ¤œè¨¼
"""

import os
import sys
import sqlite3
import json
import shutil
from datetime import datetime
from typing import List, Dict
import ollama

# ãƒ‘ã‚¹ã‚’è¿½åŠ ï¼ˆbackend/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‚ç…§ï¼‰
BACKEND_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, BACKEND_DIR)

from analyzer import ConversationAnalyzer, ProfileManager
from rag_system import RAGSystem
from finetuning import FineTuningSystem


class TestSystem:
    """ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, test_db: str = "test_partner_ai.db"):
        self.test_db = test_db
        self.chroma_test_dir = "./test_chroma_db"
        self.user_id = "test_user_001"
        self.base_model = "gemma3:4b"  # ãƒ†ã‚¹ãƒˆç”¨ã«è»½é‡ãƒ¢ãƒ‡ãƒ«
        
    def reset_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ãƒªã‚»ãƒƒãƒˆ"""
        print("\n" + "="*60)
        print("ğŸ—‘ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªã‚»ãƒƒãƒˆ")
        print("="*60)
        
        # DBãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(self.test_db):
            os.remove(self.test_db)
            print(f"âœ… {self.test_db} ã‚’å‰Šé™¤")
        
        # ChromaDBå‰Šé™¤
        if os.path.exists(self.chroma_test_dir):
            shutil.rmtree(self.chroma_test_dir)
            print(f"âœ… {self.chroma_test_dir} ã‚’å‰Šé™¤")
        
        # åˆæœŸåŒ–
        conn = sqlite3.connect(self.test_db)
        c = conn.cursor()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        c.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                user_message TEXT NOT NULL,
                ai_response TEXT NOT NULL,
                model_used TEXT,
                rating INTEGER,
                tags TEXT,
                metadata TEXT
            )
        """)
        
        c.execute("""
            CREATE TABLE IF NOT EXISTS user_profiles (
                user_id TEXT PRIMARY KEY,
                profile_data TEXT NOT NULL,
                created_at TEXT NOT NULL,
                updated_at TEXT NOT NULL
            )
        """)
        
        conn.commit()
        conn.close()
        
        print("âœ… æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–")
    
    def generate_test_conversations(self) -> List[Dict]:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        conversations = [
            # è¶£å‘³ãƒ»èˆˆå‘³ã®å­¦ç¿’
            {
                "user": "æœ€è¿‘ã€æ©Ÿæ¢°å­¦ç¿’ã®å‹‰å¼·ã‚’å§‹ã‚ãŸã‚“ã ",
                "rating": 5,
                "category": "interest"
            },
            {
                "user": "Pythonã§NeuralNetworkã‚’å®Ÿè£…ã—ãŸã„ã‚“ã ã‘ã©",
                "rating": 4,
                "category": "interest"
            },
            {
                "user": "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ¬ã§ãŠã™ã™ã‚ã‚ã‚‹ï¼Ÿ",
                "rating": 5,
                "category": "interest"
            },
            
            # å€‹äººæƒ…å ±ã®å­¦ç¿’
            {
                "user": "æ±äº¬ã§åƒã„ã¦ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãªã‚“ã ",
                "rating": 5,
                "category": "personal"
            },
            {
                "user": "é€±æœ«ã¯ã‚«ãƒ•ã‚§ã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ãŒå¥½ã",
                "rating": 4,
                "category": "personal"
            },
            
            # æŠ€è¡“çš„ãªè³ªå•
            {
                "user": "Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦æ•™ãˆã¦",
                "rating": 5,
                "category": "technical"
            },
            {
                "user": "Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã©ã†ã‚„ã£ã¦Self-attentionã¨é•ã†ã®ï¼Ÿ",
                "rating": 4,
                "category": "technical"
            },
            {
                "user": "BERTã¨GPTã®é•ã„ã‚’ç°¡å˜ã«èª¬æ˜ã—ã¦",
                "rating": 5,
                "category": "technical"
            },
            
            # è¿½åŠ ã®ä¼šè©±ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«10ä»¶ä»¥ä¸Šå¿…è¦ï¼‰
            {
                "user": "PyTorchã¨TensorFlowã©ã£ã¡ãŒã„ã„ï¼Ÿ",
                "rating": 4,
                "category": "technical"
            },
            {
                "user": "æ©Ÿæ¢°å­¦ç¿’ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§è©°ã¾ã£ã¦ã‚‹ã‚“ã ã‘ã©",
                "rating": 5,
                "category": "technical"
            },
            {
                "user": "ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã§æ°—ã‚’ã¤ã‘ã‚‹ã“ã¨ã¯ï¼Ÿ",
                "rating": 4,
                "category": "technical"
            },
            {
                "user": "éå­¦ç¿’ã‚’é˜²ãæ–¹æ³•ã‚’æ•™ãˆã¦",
                "rating": 5,
                "category": "technical"
            },
            {
                "user": "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã¯ï¼Ÿ",
                "rating": 4,
                "category": "technical"
            },
            {
                "user": "ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚ŠãŸã„",
                "rating": 5,
                "category": "technical"
            },
            {
                "user": "å¼·åŒ–å­¦ç¿’ã«ã‚‚èˆˆå‘³ãŒã‚ã‚‹ã‚“ã ",
                "rating": 4,
                "category": "interest"
            },
        ]
        
        return conversations
    
    def run_baseline_test(self, test_query: str) -> str:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆæ©Ÿèƒ½ãªã—ï¼‰ã§ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n" + "="*60)
        print("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šï¼ˆRAG/ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãªã—ï¼‰")
        print("="*60)
        
        messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
            {"role": "user", "content": test_query}
        ]
        
        response = ollama.chat(
            model=self.base_model,
            messages=messages
        )
        
        result = response['message']['content']
        print(f"\nã‚¯ã‚¨ãƒª: {test_query}")
        print(f"\nå¿œç­”:\n{result}\n")
        
        return result
    
    def run_enhanced_test(self, conversations: List[Dict], test_query: str) -> Dict:
        """æ‹¡å¼µæ©Ÿèƒ½ï¼ˆRAG + ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã§ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n" + "="*60)
        print("ğŸš€ æ‹¡å¼µæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆï¼ˆRAG + ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å­¦ç¿’ï¼‰")
        print("="*60)
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        analyzer = ConversationAnalyzer(model=self.base_model)
        rag_system = RAGSystem(persist_directory=self.chroma_test_dir)
        
        conn = sqlite3.connect(self.test_db)
        profile_manager = ProfileManager(conn)
        
        print(f"\nğŸ“ {len(conversations)}ä»¶ã®ä¼šè©±ã‚’å­¦ç¿’ä¸­...")
        
        # ä¼šè©±ã‚’å‡¦ç†
        for i, conv in enumerate(conversations, 1):
            print(f"  å‡¦ç†ä¸­: {i}/{len(conversations)} - {conv['user'][:50]}...")
            
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            messages = [
                {"role": "system", "content": "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": conv['user']}
            ]
            
            response = ollama.chat(model=self.base_model, messages=messages)
            ai_response = response['message']['content']
            
            # ä¼šè©±ã‚’DBã«ä¿å­˜
            c = conn.cursor()
            timestamp = datetime.now().isoformat()
            metadata = {"category": conv.get("category", "general")}
            
            c.execute("""
                INSERT INTO conversations 
                (user_id, timestamp, user_message, ai_response, model_used, rating, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                self.user_id, timestamp, conv['user'], ai_response,
                self.base_model, conv.get('rating'), json.dumps(metadata)
            ))
            
            conv_id = c.lastrowid
            conn.commit()
            
            # RAGã«è¿½åŠ 
            rag_system.add_memory(
                user_id=self.user_id,
                conversation_id=conv_id,
                user_message=conv['user'],
                ai_response=ai_response,
                metadata=metadata
            )
            
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
            try:
                analysis = analyzer.analyze_conversation(conv['user'], ai_response)
                profile_manager.update_profile(self.user_id, analysis)
            except:
                pass
        
        print("âœ… å­¦ç¿’å®Œäº†")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        profile = profile_manager.get_profile(self.user_id)
        print(f"\nğŸ“Š å­¦ç¿’ã—ãŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  èˆˆå‘³: {profile.get('interests', [])[:5]}")
        print(f"  è¨˜æ†¶: {len(profile.get('memories', []))}ä»¶")
        
        # RAGã§é–¢é€£è¨˜æ†¶ã‚’æ¤œç´¢
        relevant_memories = rag_system.search_relevant_memories(
            user_id=self.user_id,
            query=test_query,
            n_results=3
        )
        
        print(f"\nğŸ” é–¢é€£ã™ã‚‹è¨˜æ†¶: {len(relevant_memories)}ä»¶")
        for mem in relevant_memories:
            print(f"  - {mem['user_message'][:60]}...")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
        
        if profile.get('interests'):
            interests = ", ".join(profile['interests'][:3])
            system_prompt += f"\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³: {interests}\n"
        
        if relevant_memories:
            system_prompt += "\néå»ã®é–¢é€£ã™ã‚‹ä¼šè©±:\n"
            for mem in relevant_memories:
                system_prompt += f"- {mem['user_message'][:80]}\n"
        
        # å¿œç­”ç”Ÿæˆ
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": test_query}
        ]
        
        response = ollama.chat(model=self.base_model, messages=messages)
        result = response['message']['content']
        
        print(f"\nã‚¯ã‚¨ãƒª: {test_query}")
        print(f"\nå¿œç­”:\n{result}\n")
        
        conn.close()
        
        return {
            "response": result,
            "profile": profile,
            "relevant_memories": relevant_memories,
            "system_prompt": system_prompt
        }
    
    def run_finetuning_test(self) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n" + "="*60)
        print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
        print("="*60)
        
        tuning_system = FineTuningSystem(
            db_path=self.test_db,
            min_conversations=10
        )
        
        # æº–å‚™çŠ¶æ³ç¢ºèª
        readiness = tuning_system.get_tuning_readiness(self.user_id)
        print(f"\nğŸ“Š æº–å‚™çŠ¶æ³:")
        print(f"  ç·ä¼šè©±æ•°: {readiness['total_conversations']}")
        print(f"  é«˜è©•ä¾¡ä¼šè©±: {readiness['high_rated_conversations']}")
        print(f"  ä½¿ç”¨å¯èƒ½: {readiness['usable_for_training']}")
        print(f"  å¿…è¦æ•°: {readiness['required']}")
        print(f"  é€²æ—: {readiness['progress_percentage']:.1f}%")
        
        if not readiness['ready']:
            print("\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return {
                "status": "skipped",
                "reason": "insufficient_data",
                "readiness": readiness
            }
        
        # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        print(f"\nğŸš€ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
        print(f"  ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {self.base_model}")
        
        try:
            model_name = tuning_system.fine_tune(
                user_id=self.user_id,
                base_model=self.base_model
            )
            
            print(f"\nâœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†: {model_name}")
            
            # ãƒ†ã‚¹ãƒˆè©•ä¾¡
            test_prompts = [
                "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦",
                "Pythonã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ãŒå¥½ãï¼Ÿ",
                "æ±äº¬ã§ãŠã™ã™ã‚ã®ã‚«ãƒ•ã‚§ã¯ï¼Ÿ"
            ]
            
            print(f"\nğŸ§ª ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­...")
            evaluation = tuning_system.evaluate_model(model_name, test_prompts)
            
            print(f"\nğŸ“Š è©•ä¾¡çµæœ:")
            print(f"  æˆåŠŸç‡: {evaluation['success_rate']*100:.1f}%")
            print(f"  æˆåŠŸ: {evaluation['successful_tests']}/{evaluation['total_tests']}")
            
            for result in evaluation['results']:
                if result['success']:
                    print(f"\n  Q: {result['prompt']}")
                    print(f"  A: {result['response'][:100]}...")
            
            return {
                "status": "success",
                "model_name": model_name,
                "evaluation": evaluation,
                "readiness": readiness
            }
            
        except Exception as e:
            print(f"\nâŒ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "status": "error",
                "error": str(e),
                "readiness": readiness
            }
    
    def run_comparison_test(self, test_query: str):
        """æ¯”è¼ƒãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        print("\n" + "="*70)
        print("ğŸ”¬ æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("="*70)
        print(f"\nãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: {test_query}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªã‚»ãƒƒãƒˆ
        self.reset_database()
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        conversations = self.generate_test_conversations()
        
        # 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        baseline_response = self.run_baseline_test(test_query)
        
        # 2. æ‹¡å¼µæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        enhanced_result = self.run_enhanced_test(conversations, test_query)
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        finetuning_result = self.run_finetuning_test()
        
        # çµæœã¾ã¨ã‚
        print("\n" + "="*70)
        print("ğŸ“‹ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("="*70)
        
        print(f"\n1ï¸âƒ£  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆæ¨™æº–ãƒ¢ãƒ‡ãƒ«ï¼‰")
        print(f"   å¿œç­”é•·: {len(baseline_response)}æ–‡å­—")
        
        print(f"\n2ï¸âƒ£  æ‹¡å¼µæ©Ÿèƒ½ï¼ˆRAG + ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
        print(f"   å¿œç­”é•·: {len(enhanced_result['response'])}æ–‡å­—")
        print(f"   å­¦ç¿’ã—ãŸèˆˆå‘³: {len(enhanced_result['profile'].get('interests', []))}ä»¶")
        print(f"   å‚ç…§ã—ãŸè¨˜æ†¶: {len(enhanced_result['relevant_memories'])}ä»¶")
        
        print(f"\n3ï¸âƒ£  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
        if finetuning_result['status'] == 'success':
            print(f"   ãƒ¢ãƒ‡ãƒ«å: {finetuning_result['model_name']}")
            print(f"   è©•ä¾¡æˆåŠŸç‡: {finetuning_result['evaluation']['success_rate']*100:.1f}%")
        else:
            print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {finetuning_result['status']}")
            if finetuning_result.get('reason'):
                print(f"   ç†ç”±: {finetuning_result['reason']}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = {
            "test_query": test_query,
            "timestamp": datetime.now().isoformat(),
            "baseline": {
                "response": baseline_response,
                "length": len(baseline_response)
            },
            "enhanced": {
                "response": enhanced_result['response'],
                "length": len(enhanced_result['response']),
                "interests_learned": enhanced_result['profile'].get('interests', []),
                "memories_count": len(enhanced_result.get('relevant_memories', [])),
                "system_prompt": enhanced_result['system_prompt']
            },
            "finetuning": finetuning_result
        }
        
        report_path = f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        print("\n" + "="*70)
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("="*70)
        
        return report


# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ====================

if __name__ == "__main__":
    test_system = TestSystem()
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "æ©Ÿæ¢°å­¦ç¿’ã®å‹‰å¼·æ–¹æ³•ã§ãŠã™ã™ã‚ã‚’æ•™ãˆã¦",
        "ç§ã®è¶£å‘³ã«åˆã£ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚ã‚‹ï¼Ÿ",
        "Pythonæ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¤ã„ã¦æ•™ãˆã¦"
    ]
    
    # å„ã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    for query in test_queries:
        print(f"\n\n{'='*70}")
        print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {query}")
        print(f"{'='*70}")
        
        test_system.run_comparison_test(query)
        
        # æ¬¡ã®ãƒ†ã‚¹ãƒˆã¾ã§å°‘ã—å¾…æ©Ÿ
        input("\nâ¸ï¸  Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦æ¬¡ã®ãƒ†ã‚¹ãƒˆã¸...")