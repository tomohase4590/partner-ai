"""
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ 
æ¨™æº–çš„ãªOllamaãƒãƒ£ãƒƒãƒˆã¨ã®æ¯”è¼ƒç”¨
"""

import ollama
import json
from datetime import datetime
from typing import List, Dict


class BaselineChat:
    """æ¨™æº–çš„ãªãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ©Ÿèƒ½ãªã—ï¼‰"""
    
    def __init__(self, model: str = "gemma3:4b"):
        self.model = model
        self.conversation_history: List[Dict] = []
    
    def chat(self, user_message: str) -> str:
        """æ¨™æº–çš„ãªãƒãƒ£ãƒƒãƒˆ"""
        messages = [
            {"role": "system", "content": "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãã€æœ‰èƒ½ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
        ]
        
        # å±¥æ­´ã‚’è¿½åŠ ï¼ˆç›´è¿‘5ä»¶ã®ã¿ï¼‰
        for conv in self.conversation_history[-5:]:
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        messages.append({"role": "user", "content": user_message})
        
        # å¿œç­”ç”Ÿæˆ
        response = ollama.chat(model=self.model, messages=messages)
        ai_response = response['message']['content']
        
        # å±¥æ­´ã«ä¿å­˜
        self.conversation_history.append({
            'user': user_message,
            'assistant': ai_response,
            'timestamp': datetime.now().isoformat()
        })
        
        return ai_response
    
    def get_stats(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±"""
        if not self.conversation_history:
            return {
                "total_conversations": 0,
                "avg_response_length": 0,
                "total_tokens": 0
            }
        
        total_length = sum(len(c['assistant']) for c in self.conversation_history)
        avg_length = total_length / len(self.conversation_history)
        
        return {
            "total_conversations": len(self.conversation_history),
            "avg_response_length": round(avg_length, 1),
            "total_characters": total_length
        }


class ComparisonRunner:
    """æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    
    def __init__(self, model: str = "gemma3:4b"):
        self.baseline = BaselineChat(model)
    
    def run_conversation_set(self, conversations: List[str]) -> Dict:
        """ä¼šè©±ã‚»ãƒƒãƒˆã‚’å®Ÿè¡Œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ’¬ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä¼šè©±é–‹å§‹ï¼ˆ{len(conversations)}ä»¶ï¼‰")
        print(f"{'='*60}\n")
        
        results = []
        
        for i, user_msg in enumerate(conversations, 1):
            print(f"[{i}/{len(conversations)}] ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_msg}")
            
            response = self.baseline.chat(user_msg)
            
            print(f"            AIå¿œç­”: {response[:100]}...")
            print()
            
            results.append({
                "user": user_msg,
                "response": response,
                "length": len(response)
            })
        
        stats = self.baseline.get_stats()
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµ±è¨ˆ")
        print(f"{'='*60}")
        print(f"ç·ä¼šè©±æ•°: {stats['total_conversations']}")
        print(f"å¹³å‡å¿œç­”é•·: {stats['avg_response_length']}æ–‡å­—")
        print(f"ç·æ–‡å­—æ•°: {stats['total_characters']}")
        
        return {
            "results": results,
            "stats": stats
        }
    
    def compare_with_context(self, test_query: str, context_info: str = None) -> Dict:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Šãªã—ã®æ¯”è¼ƒ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
        print(f"{'='*60}\n")
        
        # 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—
        print("1ï¸âƒ£  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—:")
        print(f"   ã‚¯ã‚¨ãƒª: {test_query}")
        response_no_context = self.baseline.chat(test_query)
        print(f"   å¿œç­”: {response_no_context[:150]}...\n")
        
        # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Šï¼ˆæ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰
        baseline_with_context = BaselineChat(self.baseline.model)
        
        if context_info:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å…ˆã«å…¥åŠ›
            print("2ï¸âƒ£  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Š:")
            print(f"   ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context_info}")
            baseline_with_context.chat(context_info)
        
        print(f"   ã‚¯ã‚¨ãƒª: {test_query}")
        response_with_context = baseline_with_context.chat(test_query)
        print(f"   å¿œç­”: {response_with_context[:150]}...\n")
        
        return {
            "no_context": {
                "response": response_no_context,
                "length": len(response_no_context)
            },
            "with_context": {
                "response": response_with_context,
                "length": len(response_with_context),
                "context": context_info
            }
        }


def run_baseline_tests():
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    
    runner = ComparisonRunner()
    
    # ãƒ†ã‚¹ãƒˆä¼šè©±ã‚»ãƒƒãƒˆ
    test_conversations = [
        "ã“ã‚“ã«ã¡ã¯",
        "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦",
        "Pythonã§ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ãŒå¥½ããªã‚“ã ",
        "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ãŠã™ã™ã‚ã¯ï¼Ÿ",
        "æ±äº¬ã§åƒã„ã¦ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™",
        "é€±æœ«ã¯ã‚«ãƒ•ã‚§ã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™",
        "NeuralNetworkã®å®Ÿè£…æ–¹æ³•ã‚’çŸ¥ã‚ŠãŸã„",
        "Transformerã¨BERTã®é•ã„ã¯ï¼Ÿ",
    ]
    
    # ä¼šè©±ã‚»ãƒƒãƒˆå®Ÿè¡Œ
    result = runner.run_conversation_set(test_conversations)
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¯”è¼ƒ
    comparison = runner.compare_with_context(
        test_query="ç§ã«åˆã£ãŸå‹‰å¼·æ–¹æ³•ã‚’æ•™ãˆã¦",
        context_info="æ©Ÿæ¢°å­¦ç¿’ã®å‹‰å¼·ã‚’ã—ã¦ã„ã¦ã€PythonãŒå¥½ãã§ã€æ±äº¬ã®ã‚«ãƒ•ã‚§ã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ãŒè¶£å‘³ã§ã™"
    )
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = {
        "timestamp": datetime.now().isoformat(),
        "model": runner.baseline.model,
        "conversation_results": result,
        "context_comparison": comparison
    }
    
    # ä¿å­˜
    report_path = f"baseline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    return report


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã‚·ã‚¹ãƒ†ãƒ ")
    print("="*70)
    print("\næ¨™æº–çš„ãªOllamaãƒãƒ£ãƒƒãƒˆï¼ˆRAGãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å­¦ç¿’ãªã—ï¼‰")
    print("æ‹¡å¼µæ©Ÿèƒ½ã¨ã®æ¯”è¼ƒç”¨ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã™\n")
    
    report = run_baseline_tests()
    
    print("\n" + "="*70)
    print("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("="*70)